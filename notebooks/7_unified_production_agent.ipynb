{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(\"..\", \".env\"), override=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"LangSmith now uses UUID v7\", \n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Unified Production Agent\n",
    "# From-Scratch ‚Üí Enhanced ‚Üí Persistent\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "This notebook **unifies** everything from Notebooks 4, 5, and 6 into a single, \n",
    "production-ready Deep Agent with Amazon Nova (Bedrock):\n",
    "\n",
    "| Notebook | What it added | Status here |\n",
    "|----------|--------------|-------------|\n",
    "| **NB4** (Full Agent) | Base agent with todos, files, sub-agents | ‚úÖ Foundation |\n",
    "| **NB5** (Enhanced) | `edit_file`, `glob_files`, `grep_files`, Skills system | ‚úÖ Merged |\n",
    "| **NB6** (Production) | Prompt caching, DynamoDB persistence | ‚úÖ Merged |\n",
    "\n",
    "### What was fixed from NB5 + NB6 contradictions:\n",
    "\n",
    "| Issue | Resolution |\n",
    "|-------|-----------|\n",
    "| NB5 uses in-memory `write_todos` / NB6 uses `dynamo_write_todos` | ‚Üí **Unified**: DynamoDB tools for todos and basic files |\n",
    "| NB5 uses raw f-string prompt / NB6 uses `build_cached_prompt()` | ‚Üí **Unified**: Cached prompt with optimal ordering |\n",
    "| `edit_file`/`glob_files`/`grep_files` operate on in-memory only | ‚Üí **Documented**: These operate on the in-memory `state[\"files\"]` which is synced via `dynamo_write_file` |\n",
    "| Agent built twice (once in each notebook) | ‚Üí **Unified**: Single `create_agent()` call with checkpointer |\n",
    "| Same test query duplicated | ‚Üí **Unified**: Single multi-turn test |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Architecture Map\n",
    "\n",
    "### üèóÔ∏è Agents\n",
    "\n",
    "| Agent | Role | Model | Tools |\n",
    "|-------|------|-------|-------|\n",
    "| **Orchestrator** | Coordinates all work, talks to user | Nova Lite/Pro | All tools below |\n",
    "| **Research Sub-agent** | Web research with context isolation | Nova Lite | `tavily_search`, `think_tool` |\n",
    "\n",
    "### üîß Tools by Category\n",
    "\n",
    "| Category | Tool | Backend | Description |\n",
    "|----------|------|---------|-------------|\n",
    "| **Planning** | `dynamo_write_todos` | DynamoDB | Create/update TODO list (persistent) |\n",
    "| **Planning** | `dynamo_read_todos` | DynamoDB | Read current TODO list (persistent) |\n",
    "| **Files (Persistent)** | `dynamo_ls` | DynamoDB + Memory | List all files from both sources |\n",
    "| **Files (Persistent)** | `dynamo_read_file` | DynamoDB + Memory | Read file (memory-first, DynamoDB fallback) |\n",
    "| **Files (Persistent)** | `dynamo_write_file` | DynamoDB + Memory | Create/overwrite file (dual-write) |\n",
    "| **Files (Enhanced)** | `edit_file` | Memory | Find-and-replace in existing files |\n",
    "| **Files (Enhanced)** | `glob_files` | Memory | Find files by pattern |\n",
    "| **Files (Enhanced)** | `grep_files` | Memory | Search text across all files |\n",
    "| **Skills** | `load_skill` | Memory | Load a SKILL.md with detailed instructions |\n",
    "| **Research** | `tavily_search` | Web API | Web search + save results to files |\n",
    "| **Research** | `think_tool` | None | Strategic reflection and planning |\n",
    "| **Delegation** | `task` | ‚Äî | Spawn isolated sub-agent for complex tasks |\n",
    "\n",
    "### üìÅ State & Persistence\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    Agent State (RAM)                      ‚îÇ\n",
    "‚îÇ  messages: list[Message]  ‚Üê Chat history                 ‚îÇ\n",
    "‚îÇ  todos: list[Todo]        ‚Üê Task planning                ‚îÇ\n",
    "‚îÇ  files: dict[str, str]    ‚Üê Virtual filesystem           ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚îÇ Checkpointer         ‚îÇ dynamo_* tools\n",
    "             ‚ñº                       ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ DeepAgents_State   ‚îÇ  ‚îÇ DeepAgents_Artifacts           ‚îÇ\n",
    "‚îÇ (DynamoDB)         ‚îÇ  ‚îÇ (DynamoDB)                     ‚îÇ\n",
    "‚îÇ                    ‚îÇ  ‚îÇ                                ‚îÇ\n",
    "‚îÇ PK: thread_id      ‚îÇ  ‚îÇ PK: thread_id                  ‚îÇ\n",
    "‚îÇ SK: checkpoint_id   ‚îÇ  ‚îÇ SK: artifact_id                ‚îÇ\n",
    "‚îÇ                    ‚îÇ  ‚îÇ     FILE#main.py               ‚îÇ\n",
    "‚îÇ Persists: messages,‚îÇ  ‚îÇ     TODO#LIST                  ‚îÇ\n",
    "‚îÇ channel values     ‚îÇ  ‚îÇ                                ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: What are Skills? (SKILL.md)\n",
    "\n",
    "**Skills** are filesystem-based instruction sets for extending agent capabilities without adding more tools.\n",
    "\n",
    "### How they work (Progressive Disclosure):\n",
    "\n",
    "1. Agent sees only **name + description** in its system prompt (saves tokens)\n",
    "2. Agent calls `load_skill(\"web-research\")` when it decides the skill is relevant\n",
    "3. Full instructions load on demand\n",
    "\n",
    "### SKILL.md Format:\n",
    "\n",
    "```yaml\n",
    "---\n",
    "name: web-research\n",
    "description: Use this skill for research tasks requiring web searches.\n",
    "---\n",
    "\n",
    "# Instructions\n",
    "1. Plan your research queries\n",
    "2. Execute searches with tavily_search\n",
    "3. Reflect after each search using think_tool\n",
    "4. Synthesize and deliver findings\n",
    "```\n",
    "\n",
    "> **Note:** The `deepagents` library doesn't include skills in its installed version.\n",
    "> This is our from-scratch implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Prompt Caching for Nova\n",
    "\n",
    "Amazon Nova supports **prompt caching** ‚Äî the system prompt is cached after Turn 1, \n",
    "so subsequent turns only pay **10% of the input cost** for the cached prefix.\n",
    "\n",
    "### Key Rule: Prompt Ordering\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  STATIC CONTENT (cached, pay 10%)        ‚îÇ\n",
    "‚îÇ  ‚îú‚îÄ‚îÄ Base instructions (persona, rules)  ‚îÇ\n",
    "‚îÇ  ‚îú‚îÄ‚îÄ Tool usage rules                    ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ Skills listing                      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ cachePoint ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ\n",
    "‚îÇ  DYNAMIC CONTENT (re-processed, 100%)    ‚îÇ\n",
    "‚îÇ  ‚îú‚îÄ‚îÄ Today's date                        ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ Session-specific context            ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "`ChatBedrockConverse.create_cache_point()` ‚Üí `{'cachePoint': {'type': 'default'}}` in `SystemMessage.additional_kwargs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from deep_agents_from_scratch.prompt_caching import (\n",
    "    create_cached_system_message,\n",
    "    build_cached_prompt,\n",
    "    estimate_cache_savings,\n",
    ")\n",
    "\n",
    "# --- How the cache point works ---\n",
    "cache_point = ChatBedrockConverse.create_cache_point()\n",
    "print(\"Cache point structure:\", cache_point)\n",
    "\n",
    "# --- Cost savings estimate (5000-token system prompt, 10 turns) ---\n",
    "savings = estimate_cache_savings(prompt_tokens=5000, turns_per_session=10)\n",
    "print(f\"\\nüìä Cache Savings:\")\n",
    "print(f\"   Without cache: ${savings['uncached_cost']:.4f}\")\n",
    "print(f\"   With cache:    ${savings['cached_cost']:.4f}\")\n",
    "print(f\"   Savings:       ${savings['savings']:.4f} ({savings['savings_percent']}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: DynamoDB Setup\n",
    "\n",
    "### Tables\n",
    "\n",
    "| Table | PK | SK | Purpose |\n",
    "|-------|----|----|--------|\n",
    "| `DeepAgents_State` | `pk` (thread_id) | `sk` (checkpoint_id) | LangGraph state (chat history, channel values) |\n",
    "| `DeepAgents_Artifacts` | `thread_id` | `artifact_id` | Persistent TODOs (`TODO#LIST`) and Files (`FILE#<path>`) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_agents_from_scratch.checkpoint_dynamo import (\n",
    "    create_dynamodb_tables,\n",
    "    wait_for_tables,\n",
    "    get_checkpointer,\n",
    "    DEFAULT_STATE_TABLE,\n",
    "    DEFAULT_ARTIFACTS_TABLE,\n",
    ")\n",
    "\n",
    "# Create tables (idempotent ‚Äî safe to run multiple times)\n",
    "results = create_dynamodb_tables(region_name=\"us-east-1\")\n",
    "print(\"Table creation results:\")\n",
    "for table, status in results.items():\n",
    "    print(f\"  {table}: {status}\")\n",
    "\n",
    "# Wait for tables to be ready\n",
    "wait_for_tables(region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the checkpointer (auto-detects official package or uses fallback)\n",
    "checkpointer = get_checkpointer(\n",
    "    table_name=DEFAULT_STATE_TABLE,\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "print(f\"Checkpointer type: {type(checkpointer).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Model & All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from utils import format_messages, show_prompt, stream_agent\n",
    "\n",
    "# --- Model ---\n",
    "llm_nova_lite = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-2-lite-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "llm_nova_pro = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-2-pro-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Choose model (lite for testing, pro for production)\n",
    "model = llm_nova_lite\n",
    "print(f\"‚úÖ Model: {model.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- State ---\n",
    "from deep_agents_from_scratch.state import DeepAgentState, Todo\n",
    "\n",
    "# --- Persistent TODO Tools (DynamoDB) ---\n",
    "from deep_agents_from_scratch.dynamo_tools import (\n",
    "    dynamo_write_todos,\n",
    "    dynamo_read_todos,\n",
    "    dynamo_write_file,\n",
    "    dynamo_read_file,\n",
    "    dynamo_ls,\n",
    ")\n",
    "\n",
    "# --- Enhanced File Tools (in-memory, operate on state[\"files\"]) ---\n",
    "from deep_agents_from_scratch.enhanced_file_tools import edit_file, glob_files, grep_files\n",
    "\n",
    "# --- Research Tools ---\n",
    "from deep_agents_from_scratch.research_tools import tavily_search, think_tool\n",
    "\n",
    "# --- Skills ---\n",
    "from deep_agents_from_scratch.skills import (\n",
    "    load_skill,\n",
    "    discover_skills,\n",
    "    get_skills_system_prompt,\n",
    "    RESEARCH_SKILL_MD,\n",
    "    CODE_REVIEW_SKILL_MD,\n",
    ")\n",
    "\n",
    "# --- Sub-agent construction ---\n",
    "from deep_agents_from_scratch.task_tool import _create_task_tool, SubAgent\n",
    "\n",
    "# --- Prompts ---\n",
    "from deep_agents_from_scratch.prompts import (\n",
    "    RESEARCHER_INSTRUCTIONS,\n",
    "    TODO_USAGE_INSTRUCTIONS,\n",
    "    FILE_USAGE_INSTRUCTIONS,\n",
    "    SUBAGENT_USAGE_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "# --- Prompt Caching ---\n",
    "from deep_agents_from_scratch.prompt_caching import build_cached_prompt\n",
    "\n",
    "print(\"‚úÖ All components imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Review All Tools\n",
    "\n",
    "### Persistent Tools (DynamoDB-backed)\n",
    "These tools write to both in-memory state AND DynamoDB for cross-session persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üì¶ PERSISTENT TOOLS (DynamoDB)\")\n",
    "print(\"=\" * 60)\n",
    "for t in [dynamo_write_todos, dynamo_read_todos, dynamo_ls, dynamo_read_file, dynamo_write_file]:\n",
    "    print(f\"\\nüîß {t.name}\")\n",
    "    print(f\"   {t.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced File Tools (in-memory)\n",
    "\n",
    "These tools operate on `state[\"files\"]` only. Since `dynamo_write_file` already syncs \n",
    "files to both memory and DynamoDB, these tools can search/edit the in-memory copy,\n",
    "and any modifications are available for the persistent tools to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üîç ENHANCED FILE TOOLS (in-memory)\")\n",
    "print(\"=\" * 60)\n",
    "for t in [edit_file, glob_files, grep_files]:\n",
    "    print(f\"\\nüîß {t.name}\")\n",
    "    print(f\"   {t.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üìã SKILLS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüîß {load_skill.name}\")\n",
    "print(f\"   {load_skill.description[:150]}...\")\n",
    "\n",
    "# Preview example skills\n",
    "from deep_agents_from_scratch.skills import parse_skill_md\n",
    "\n",
    "for skill_md, label in [(RESEARCH_SKILL_MD, \"web-research\"), (CODE_REVIEW_SKILL_MD, \"code-review\")]:\n",
    "    parsed = parse_skill_md(skill_md)\n",
    "    print(f\"\\n   üìã {parsed['name']}: {parsed['description'][:70]}...\")\n",
    "    print(f\"      Instructions: {len(parsed['instructions'])} chars (loaded on demand)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Build the Production Agent\n",
    "\n",
    "This is the single, unified agent construction ‚Äî combining:\n",
    "- **NB4's** base pattern (`create_agent` + sub-agents)\n",
    "- **NB5's** enhanced tools and skills\n",
    "- **NB6's** DynamoDB persistence and prompt caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- All orchestrator tools ---\n",
    "orchestrator_tools = [\n",
    "    # Planning (DynamoDB-persistent)\n",
    "    dynamo_write_todos,\n",
    "    dynamo_read_todos,\n",
    "    # Files: persistent (DynamoDB + memory)\n",
    "    dynamo_ls,\n",
    "    dynamo_read_file,\n",
    "    dynamo_write_file,\n",
    "    # Files: enhanced (in-memory, works on synced state)\n",
    "    edit_file,\n",
    "    glob_files,\n",
    "    grep_files,\n",
    "    # Skills\n",
    "    load_skill,\n",
    "    # Thinking\n",
    "    think_tool,\n",
    "]\n",
    "\n",
    "# --- Sub-agents (from NB4) ---\n",
    "subagents = [\n",
    "    SubAgent(\n",
    "        name=\"research-agent\",\n",
    "        description=\"Delegated research agent for complex web searches. Has tavily_search and think_tool.\",\n",
    "        prompt=RESEARCHER_INSTRUCTIONS.format(date=datetime.now().strftime(\"%a %b %-d, %Y\")),\n",
    "        tools=[\"tavily_search\", \"think_tool\"],\n",
    "    ),\n",
    "]\n",
    "\n",
    "# --- Create task delegation tool ---\n",
    "all_tools_for_registry = orchestrator_tools + [tavily_search]\n",
    "task_tool = _create_task_tool(\n",
    "    tools=all_tools_for_registry,\n",
    "    subagents=subagents,\n",
    "    model=model,\n",
    "    state_schema=DeepAgentState,\n",
    ")\n",
    "\n",
    "# Final tool list\n",
    "final_tools = orchestrator_tools + [task_tool]\n",
    "\n",
    "print(f\"‚úÖ Orchestrator: {len(final_tools)} tools\")\n",
    "for t in final_tools:\n",
    "    print(f\"   üîß {t.name}\")\n",
    "print(f\"\\n‚úÖ Sub-agents: {len(subagents)}\")\n",
    "for sa in subagents:\n",
    "    print(f\"   ü§ñ {sa.name}: {sa.description[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build Cached System Prompt ---\n",
    "# Order: static (cached after Turn 1) ‚Üí cache point ‚Üí dynamic (re-processed each turn)\n",
    "\n",
    "BASE_INSTRUCTIONS = \"\"\"You are a highly capable AI assistant with planning, research, file management, and skills capabilities.\n",
    "\n",
    "You operate in PERSISTENT MODE:\n",
    "- Your TODOs are saved to DynamoDB via dynamo_write_todos / dynamo_read_todos\n",
    "- Your files are saved to DynamoDB via dynamo_write_file / dynamo_read_file / dynamo_ls  \n",
    "- Your conversation history persists across sessions via thread_id\n",
    "- Always pass the thread_id parameter when using dynamo_* tools\n",
    "\n",
    "For file editing (edit_file, glob_files, grep_files), these operate on the in-memory \n",
    "copy of files. Use dynamo_write_file first to create files, then use these tools to \n",
    "search and edit them.\"\"\"\n",
    "\n",
    "TOOL_INSTRUCTIONS = f\"\"\"{TODO_USAGE_INSTRUCTIONS}\n",
    "\n",
    "{FILE_USAGE_INSTRUCTIONS}\n",
    "\n",
    "{SUBAGENT_USAGE_INSTRUCTIONS.format(max_concurrent_research_units=3, max_researcher_iterations=3)}\n",
    "\n",
    "## Skills System\n",
    "You have access to a skills system. Skills are specialized instruction sets loaded from SKILL.md files.\n",
    "- Use dynamo_ls() to discover available skills in the filesystem\n",
    "- Use load_skill(name) to read full instructions when a skill is relevant\n",
    "- Skills provide step-by-step guidance for specific tasks (research, code review, etc.)\"\"\"\n",
    "\n",
    "DYNAMIC_CONTEXT = f\"Today's date is {datetime.now().strftime('%A %B %-d, %Y')}.\"\n",
    "\n",
    "# Build with optimal caching structure\n",
    "cached_system_msg = build_cached_prompt(\n",
    "    base_instructions=BASE_INSTRUCTIONS,\n",
    "    tool_usage_instructions=TOOL_INSTRUCTIONS,\n",
    "    dynamic_context=DYNAMIC_CONTEXT,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ System prompt: {len(cached_system_msg.content)} chars\")\n",
    "print(f\"   Cache point: {cached_system_msg.additional_kwargs}\")\n",
    "print(f\"   ‚Üí Static prefix cached after Turn 1 (90% cost savings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# --- Create the Unified Production Agent ---\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    system_prompt=cached_system_msg.content,\n",
    "    tools=final_tools,\n",
    "    state_schema=DeepAgentState,\n",
    "    checkpointer=checkpointer,  # DynamoDB state persistence!\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Production agent created!\")\n",
    "print(f\"   Model:        {model.model}\")\n",
    "print(f\"   Tools:        {len(final_tools)}\")\n",
    "print(f\"   Sub-agents:   {len(subagents)}\")\n",
    "print(f\"   Checkpointer: {type(checkpointer).__name__}\")\n",
    "print(f\"   Cache:        Prompt caching enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the agent graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Pre-load Skills into the Virtual Filesystem\n",
    "\n",
    "We seed the virtual filesystem with SKILL.md files. The agent discovers them via `dynamo_ls()` \n",
    "and loads them on-demand via `load_skill()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-load skills into the virtual filesystem\n",
    "initial_files = {\n",
    "    \"/skills/web-research/SKILL.md\": RESEARCH_SKILL_MD,\n",
    "    \"/skills/code-review/SKILL.md\": CODE_REVIEW_SKILL_MD,\n",
    "}\n",
    "\n",
    "# Verify skill discovery works\n",
    "discovered = discover_skills(initial_files)\n",
    "print(\"üìã Discovered Skills:\")\n",
    "for s in discovered:\n",
    "    print(f\"   ‚Ä¢ {s['name']}: {s['description'][:80]}...\")\n",
    "\n",
    "# Show the skills system prompt (progressive disclosure)\n",
    "skills_prompt = get_skills_system_prompt(initial_files)\n",
    "print(f\"\\nüìù Skills Prompt ({len(skills_prompt)} chars):\")\n",
    "print(skills_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Multi-Turn Test with Persistence\n",
    "\n",
    "This demonstrates the key production features:\n",
    "1. **Turn 1**: Agent receives a research request, creates TODOs, delegates research\n",
    "2. **Turn 2**: Agent remembers context from Turn 1 (via DynamoDB checkpointer)\n",
    "3. Files and TODOs persist in DynamoDB across both turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Create a unique thread for this session\n",
    "thread_id = f\"session_{uuid.uuid4().hex[:8]}\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "print(f\"üßµ Thread ID: {thread_id}\")\n",
    "print(f\"   Reuse this ID to resume the conversation later!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Turn 1: Research request ---\n",
    "query_1 = \"Give me an overview of Model Context Protocol (MCP).\"\n",
    "\n",
    "result_1 = await stream_agent(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query_1}],\n",
    "        \"files\": initial_files,  # Pre-load skills\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Turn 1 results\n",
    "print(\"=\" * 60)\n",
    "print(\"TURN 1 RESPONSE\")\n",
    "print(\"=\" * 60)\n",
    "print(result_1[\"messages\"][-1].content[:1000])\n",
    "\n",
    "print(f\"\\nüìÅ Files: {list(result_1.get('files', {}).keys())[:5]}\")\n",
    "\n",
    "print(\"\\nüìã TODOs:\")\n",
    "for todo in result_1.get(\"todos\", []):\n",
    "    status_emoji = {\"pending\": \"‚è≥\", \"in_progress\": \"üîÑ\", \"completed\": \"‚úÖ\"}\n",
    "    emoji = status_emoji.get(todo[\"status\"], \"‚ùì\")\n",
    "    print(f\"   {emoji} {todo['content']} ({todo['status']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Turn 2: Follow-up (agent remembers Turn 1 context) ---\n",
    "query_2 = \"Based on your research, what are the main security concerns with MCP?\"\n",
    "\n",
    "result_2 = await stream_agent(\n",
    "    agent,\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query_2}]},\n",
    "    config=config,  # Same thread_id ‚Üí same conversation!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Turn 2 results\n",
    "print(\"=\" * 60)\n",
    "print(\"TURN 2 RESPONSE (uses Turn 1 context via DynamoDB)\")\n",
    "print(\"=\" * 60)\n",
    "print(result_2[\"messages\"][-1].content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Verify DynamoDB Persistence\n",
    "\n",
    "Let's query DynamoDB directly to confirm everything was persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "dynamodb = boto3.resource(\"dynamodb\", region_name=\"us-east-1\")\n",
    "\n",
    "# Check State table (checkpoints)\n",
    "state_table = dynamodb.Table(\"DeepAgents_State\")\n",
    "state_response = state_table.query(\n",
    "    KeyConditionExpression=Key(\"pk\").eq(thread_id),\n",
    "    Limit=5,\n",
    ")\n",
    "print(f\"üìä Checkpoints for thread '{thread_id}': {state_response['Count']}\")\n",
    "\n",
    "# Check Artifacts table (TODOs + Files)\n",
    "artifacts_table = dynamodb.Table(\"DeepAgents_Artifacts\")\n",
    "artifacts_response = artifacts_table.query(\n",
    "    KeyConditionExpression=Key(\"thread_id\").eq(thread_id),\n",
    ")\n",
    "print(f\"\\nüìä Artifacts for thread '{thread_id}':\")\n",
    "for item in artifacts_response.get(\"Items\", []):\n",
    "    artifact_id = item[\"artifact_id\"]\n",
    "    content_preview = item.get(\"content\", \"\")[:80]\n",
    "    updated = item.get(\"updated_at\", \"?\")\n",
    "    print(f\"   {artifact_id} (updated: {updated})\")\n",
    "    print(f\"      {content_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 11: Test Enhanced File Tools\n",
    "\n",
    "These tools operate on the in-memory `state[\"files\"]`, which is synced with DynamoDB\n",
    "via `dynamo_write_file`. Let's verify they work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick manual test of enhanced file tools\n",
    "from deep_agents_from_scratch.enhanced_file_tools import edit_file, glob_files, grep_files\n",
    "\n",
    "# Simulate a state with test files\n",
    "test_state = {\n",
    "    \"files\": {\n",
    "        \"notes.md\": \"# Notes\\n\\nHello World\\nThis is a test.\",\n",
    "        \"findings_mcp.md\": \"# MCP Findings\\n\\nMCP is a protocol for AI tool communication.\",\n",
    "        \"findings_rag.md\": \"# RAG Findings\\n\\nRAG is retrieval augmented generation.\",\n",
    "        \"readme.txt\": \"Just a readme file.\",\n",
    "    },\n",
    "    \"messages\": [],\n",
    "}\n",
    "\n",
    "# Test glob_files (find by pattern)\n",
    "print(\"üîç glob_files('findings_*'):\")\n",
    "glob_result = glob_files.invoke(\n",
    "    {\"pattern\": \"findings_*\"}, \n",
    "    config={\"configurable\": {\"state\": test_state}}\n",
    ")\n",
    "print(f\"   {glob_result}\")\n",
    "\n",
    "# Test grep_files (search text)\n",
    "print(\"\\nüîç grep_files('protocol'):\")\n",
    "grep_result = grep_files.invoke(\n",
    "    {\"pattern\": \"protocol\"}, \n",
    "    config={\"configurable\": {\"state\": test_state}}\n",
    ")\n",
    "print(f\"   {grep_result}\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced file tools working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 12: Complete Architecture Summary\n",
    "\n",
    "### What This Agent Has\n",
    "\n",
    "| Category | Tool | Backend | From |\n",
    "|----------|------|---------|------|\n",
    "| **Planning** | `dynamo_write_todos` | DynamoDB | NB6 |\n",
    "| **Planning** | `dynamo_read_todos` | DynamoDB | NB6 |\n",
    "| **Files** | `dynamo_ls` | DynamoDB + Memory | NB6 |\n",
    "| **Files** | `dynamo_read_file` | DynamoDB + Memory | NB6 |\n",
    "| **Files** | `dynamo_write_file` | DynamoDB + Memory | NB6 |\n",
    "| **Files** | `edit_file` | Memory | NB5 |\n",
    "| **Files** | `glob_files` | Memory | NB5 |\n",
    "| **Files** | `grep_files` | Memory | NB5 |\n",
    "| **Skills** | `load_skill` | Memory | NB5 |\n",
    "| **Research** | `tavily_search` | Web API | NB4 |\n",
    "| **Research** | `think_tool` | None | NB4 |\n",
    "| **Delegation** | `task` | ‚Äî | NB4 |\n",
    "\n",
    "### Production Features\n",
    "\n",
    "| Feature | Implementation | Savings |\n",
    "|---------|---------------|---------|\n",
    "| **Prompt Caching** | `build_cached_prompt()` + `cachePoint` | 90% cost, 85% latency |\n",
    "| **State Persistence** | DynamoDB checkpointer | Resume conversations |\n",
    "| **Artifact Persistence** | `dynamo_*` tools | TODOs + Files survive restarts |\n",
    "| **Skills** | SKILL.md + `load_skill` | Progressive disclosure |\n",
    "| **Context Isolation** | `task` tool (sub-agents) | Clean research contexts |\n",
    "\n",
    "### What the Library Has That We Don't (Yet)\n",
    "\n",
    "- `execute` tool (sandboxed command execution)\n",
    "- `PatchToolCallsMiddleware` (fixing orphaned tool calls)\n",
    "- `SummarizationMiddleware` (compressing long conversation contexts)\n",
    "- Multiple filesystem backends (disk, store, composite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}