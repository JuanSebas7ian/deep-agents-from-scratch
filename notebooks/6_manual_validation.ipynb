{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "dab2c783",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Setup Complete. Root: /home/juansebas7ian/deep-agents-from-scratch\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# SETUP\n",
                "# =============================================================================\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import os\n",
                "import sys\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Add project root to path\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "load_dotenv()\n",
                "\n",
                "print(f\"‚úÖ Setup Complete. Root: {os.path.abspath('..')}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "110aac71",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- 1. Testing Write ---\n",
                        "Write Result: Success: Task 'Unit Test Task: Validate DynamoDB Client' saved.\n",
                        "\n",
                        "--- 2. Testing Read ---\n",
                        "Context Fetched: {'profile': {}, 'todos': [{'user_id': 'user_val_test', 'description': 'Unit Test Task: Validate DynamoDB Client', 'status': 'pending', 'task_id': '0a1ed834'}, {'user_id': 'user_val_test', 'description': 'Unit Test Task: Validate DynamoDB Client', 'status': 'pending', 'task_id': '319895e7'}, {'user_id': 'user_val_test', 'description': 'Unit Test Task: Validate DynamoDB Client', 'status': 'pending', 'task_id': '517b7ed0'}, {'user_id': 'user_val_test', 'description': 'Unit Test Task: Validate DynamoDB Client', 'status': 'pending', 'task_id': '62a14266'}]}\n",
                        "\n",
                        "‚úÖ STEP 1 SUCCESS: Task written and retrieved from DynamoDB.\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# PASO 1: VALIDAR EL \"M√öSCULO\" (DynamoDB)\n",
                "# =============================================================================\n",
                "# Validamos neuro_agent/src/dynamo_client.py\n",
                "\n",
                "try:\n",
                "    from neuro_agent.src.adapters.dynamo_client import write_task_to_dynamo, fetch_context_from_dynamo\n",
                "    \n",
                "    USER_TEST_ID = \"user_val_test\"\n",
                "    TASK_DESC = \"Unit Test Task: Validate DynamoDB Client\"\n",
                "    \n",
                "    print(\"\\n--- 1. Testing Write ---\")\n",
                "    # write_task_to_dynamo is a @tool, so we invoke it or call it directly if possible.\n",
                "    # It returns a string.\n",
                "    try:\n",
                "        if hasattr(write_task_to_dynamo, 'invoke'):\n",
                "             # If it's a StructuredTool\n",
                "             write_result = write_task_to_dynamo.invoke({'user_id': USER_TEST_ID, 'task_description': TASK_DESC})\n",
                "        else:\n",
                "             write_result = write_task_to_dynamo(USER_TEST_ID, TASK_DESC)\n",
                "    except Exception as ie:\n",
                "        # Fallback if arguments are positional but tool expects kwarg dictionary for invoke\n",
                "         write_result = write_task_to_dynamo.invoke({'user_id': USER_TEST_ID, 'task_description': TASK_DESC})\n",
                "\n",
                "    print(f\"Write Result: {write_result}\")\n",
                "    \n",
                "    print(\"\\n--- 2. Testing Read ---\")\n",
                "    context = fetch_context_from_dynamo(USER_TEST_ID)\n",
                "    print(f\"Context Fetched: {context}\")\n",
                "    \n",
                "    # Assert\n",
                "    todos = context.get(\"todos\", [])\n",
                "    found = any(t.get('description') == TASK_DESC for t in todos)\n",
                "    \n",
                "    if found:\n",
                "        print(\"\\n‚úÖ STEP 1 SUCCESS: Task written and retrieved from DynamoDB.\")\n",
                "    else:\n",
                "        print(\"\\n‚ùå STEP 1 FAILED: Task not found in fetched context.\")\n",
                "        \n",
                "except ImportError as e:\n",
                "    print(f\"\\n‚ùå IMPORT ERROR: {e}\")\n",
                "    print(\"Ensure neuro_agent/src/dynamo_client.py exists and is in the python path.\")\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ùå EXECUTION ERROR: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "7a0a3b26",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Added /home/juansebas7ian/deep-agents-from-scratch/neuro_agent to sys.path\n",
                        "\n",
                        "--- Testing Lambda Handler ---\n",
                        "Invoking lambda_handler with event: {'user_id': 'user_val_test', 'explicit_instructions': 'Execute unit test task: Buy milk via Lambda'}\n",
                        "Response: {'statusCode': 200, 'body': \"[{'type': 'text', 'text': '<thinking> The User has asked to execute a unit test task to buy milk via AWS Lambda. This task can be written to the database using the provided tool `write_task_to_dynamo`. </thinking>\\\\n'}, {'type': 'tool_use', 'name': 'write_task_to_dynamo', 'input': {'task_description': 'Execute unit test task: Buy milk via Lambda', 'user_id': 'user_val_test'}, 'id': 'tooluse_KOHotORUR4eDBP5A85c3gB'}]\"}\n",
                        "\n",
                        "‚úÖ STEP 2 SUCCESS: Executor Handler executed successfully and returned 200.\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# PASO 2: VALIDAR EL \"AGENTE IDIOTA\" (Executor Handler)\n",
                "# =============================================================================\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Add neuro_agent to path to allow 'from src.dynamo_client import ...' inside lambda_executor.py\n",
                "project_root = os.path.abspath('..')\n",
                "neuro_agent_dir = os.path.join(project_root, 'neuro_agent')\n",
                "\n",
                "if neuro_agent_dir not in sys.path:\n",
                "    sys.path.append(neuro_agent_dir)\n",
                "    print(f\"Added {neuro_agent_dir} to sys.path\")\n",
                "\n",
                "try:\n",
                "    # Import the handler. 'neuro_agent/deploy/lambda_executor.py' imports 'src.dynamo_client'.\n",
                "    # 'src' is in 'neuro_agent'. So 'import src' works inside 'lambda_executor.py' because we added 'neuro_agent' to sys.path.\n",
                "    # However, 'deploy' is also in 'neuro_agent'.\n",
                "    # So 'from deploy.lambda_executor import lambda_handler' should work if we import relative to 'neuro_agent'.\n",
                "    \n",
                "    # Let's try importing as if we are in 'neuro_agent'.\n",
                "    from deploy.lambda_executor import lambda_handler\n",
                "    \n",
                "    print(\"\\n--- Testing Lambda Handler ---\")\n",
                "    USER_TEST_ID = \"user_val_test\"\n",
                "    INSTRUCTION = \"Execute unit test task: Buy milk via Lambda\"\n",
                "    \n",
                "    mock_event = {\n",
                "        \"user_id\": USER_TEST_ID,\n",
                "        \"explicit_instructions\": INSTRUCTION\n",
                "    }\n",
                "    \n",
                "    print(f\"Invoking lambda_handler with event: {mock_event}\")\n",
                "    # Invoke synchronously\n",
                "    response = lambda_handler(mock_event, None)\n",
                "    print(f\"Response: {response}\")\n",
                "    \n",
                "    if response.get('statusCode') == 200:\n",
                "        print(\"\\n‚úÖ STEP 2 SUCCESS: Executor Handler executed successfully and returned 200.\")\n",
                "    else:\n",
                "        print(f\"\\n‚ùå STEP 2 FAILED: Response code {response.get('statusCode')}\")\n",
                "\n",
                "except ImportError as e:\n",
                "    print(f\"\\n‚ùå IMPORT ERROR: {e}\")\n",
                "    print(\"Ensure 'neuro_agent' directory is correctly added to sys.path\")\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ùå EXECUTION ERROR: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "step3_scrape",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- 3. Testing Scrape Tool ---\n",
                        "Scraping https://example.com...\n",
                        "Result Snippet: URL: https://example.com\n",
                        "\n",
                        "Example Domain\n",
                        "\n",
                        "Example Domain\n",
                        "==============\n",
                        "\n",
                        "This domain is for use in documentation examples without needing permission. Avoid use in operations.\n",
                        "\n",
                        "[Learn more](https://ian...\n",
                        "\n",
                        "‚úÖ STEP 3 SUCCESS: Scrape tool fetched content correctly.\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# PASO 3: VALIDAR HERRAMIENTAS INDIVIDUALES (Scrape)\n",
                "# =============================================================================\n",
                "from neuro_agent.src.tools import scrape_webpage\n",
                "\n",
                "print(\"\\n--- 3. Testing Scrape Tool ---\")\n",
                "URL = \"https://example.com\"\n",
                "print(f\"Scraping {URL}...\")\n",
                "try:\n",
                "    # FIX: Use .invoke() for StructuredTools\n",
                "    result = scrape_webpage.invoke({\"url\": URL})\n",
                "    print(f\"Result Snippet: {result[:200]}...\")\n",
                "\n",
                "    if \"Example Domain\" in result:\n",
                "        print(\"\\n‚úÖ STEP 3 SUCCESS: Scrape tool fetched content correctly.\")\n",
                "    else:\n",
                "        print(\"\\n‚ùå STEP 3 FAILED: Content validation failed.\")\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ùå STEP 3 ERROR: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "step4_supervisor",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- 4. Testing Supervisor Agent Flow ---\n",
                        "Invoking Agent with query: 'Give me a brief overview of Model Context Protocol (MCP) using a web search. Read the docs if possible.'\n",
                        "Observing tool calls... (Expecting: tavily_search -> scrape_webpage)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_3491/2555983428.py:19: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
                        "  agent = create_react_agent(llm, tools=tools)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîß Tool Call: tavily_search\n",
                        "üîß Tool Call: scrape_webpage\n",
                        "ü§ñ Answer Snippet: The Model Context Protocol (MCP) is an open-source standard designed to connect AI applications to e...\n",
                        "\n",
                        "--- Validation Report ---\n",
                        "‚úÖ STEP 4 SUCCESS: Agent used Search AND Scrape!\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# PASO 4: VALIDAR EL \"CEREBRO\" (Supervisor + Tools Agnostiocas)\n",
                "# =============================================================================\n",
                "from langchain_aws import ChatBedrockConverse\n",
                "from langgraph.prebuilt import create_react_agent\n",
                "from langchain_core.messages import HumanMessage\n",
                "from neuro_agent.src.tools import (\n",
                "    tavily_search, think_tool, ls, read_file, write_file, \n",
                "    write_todos, read_todos, get_today_str, scrape_webpage\n",
                ")\n",
                "\n",
                "print(\"\\n--- 4. Testing Supervisor Agent Flow ---\")\n",
                "\n",
                "# 1. Setup Model & Tools\n",
                "llm = ChatBedrockConverse(model=\"us.amazon.nova-pro-v1:0\", region_name=\"us-east-1\", temperature=0.0)\n",
                "tools = [ls, read_file, write_file, write_todos, read_todos, think_tool, tavily_search, scrape_webpage]\n",
                "\n",
                "# 2. Create Agent\n",
                "agent = create_react_agent(llm, tools=tools)\n",
                "\n",
                "# 3. Run Query\n",
                "USER_QUERY = \"Give me a brief overview of Model Context Protocol (MCP) using a web search. Read the docs if possible.\"\n",
                "print(f\"Invoking Agent with query: '{USER_QUERY}'\")\n",
                "print(\"Observing tool calls... (Expecting: tavily_search -> scrape_webpage)\")\n",
                "\n",
                "try:\n",
                "    stream = agent.stream(\n",
                "        {\"messages\": [HumanMessage(content=USER_QUERY)]},\n",
                "        stream_mode=\"values\"\n",
                "    )\n",
                "\n",
                "    tool_calls_observed = set()\n",
                "\n",
                "    for event in stream:\n",
                "        if \"messages\" in event:\n",
                "            last_msg = event[\"messages\"][-1]\n",
                "            \n",
                "            # Check for Tool Calls\n",
                "            tool_calls = getattr(last_msg, 'tool_calls', [])\n",
                "            if tool_calls:\n",
                "                for tc in tool_calls:\n",
                "                    tool_name = tc['name']\n",
                "                    print(f\"üîß Tool Call: {tool_name}\")\n",
                "                    tool_calls_observed.add(tool_name)\n",
                "            \n",
                "            # Check for Content\n",
                "            if hasattr(last_msg, 'content') and last_msg.content and not tool_calls:\n",
                "                 if last_msg.type == 'ai':\n",
                "                    print(f\"ü§ñ Answer Snippet: {last_msg.content[:100]}...\")\n",
                "\n",
                "    # 4. Assertions\n",
                "    print(\"\\n--- Validation Report ---\")\n",
                "    if 'tavily_search' in tool_calls_observed and 'scrape_webpage' in tool_calls_observed:\n",
                "        print(\"‚úÖ STEP 4 SUCCESS: Agent used Search AND Scrape!\")\n",
                "    elif 'tavily_search' in tool_calls_observed:\n",
                "        print(\"‚ö†Ô∏è STEP 4 WARNING: Agent searched but did NOT scrape.\")\n",
                "    else:\n",
                "        print(f\"‚ùå STEP 4 FAILURE: Missing critical tools. Observed: {tool_calls_observed}\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ùå STEP 4 ERROR: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "65a49dcd",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
