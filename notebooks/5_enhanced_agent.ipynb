{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(\"..\", \".env\"), override=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"LangSmith now uses UUID v7\", \n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Enhanced Deep Agent ‚Äî Full Architecture\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook documents **every component** of our Deep Agent architecture and adds enhancements inspired by the official `deepagents` library, adapted for **Amazon Nova (Bedrock)**.\n",
    "\n",
    "### Why from-scratch instead of the library?\n",
    "\n",
    "The `deepagents` library is designed for **Anthropic/Claude**:\n",
    "- `AnthropicPromptCachingMiddleware` ‚Äî incompatible with Nova\n",
    "- Default model hardcoded to `ChatAnthropic(claude-sonnet-4-5)`\n",
    "- No built-in web search tools (our `tavily_search` is custom)\n",
    "\n",
    "By building from-scratch, we get:\n",
    "- ‚úÖ Full Nova/Bedrock compatibility\n",
    "- ‚úÖ Custom web search with `tavily_search`\n",
    "- ‚úÖ Same architectural patterns (todos, files, subagents)\n",
    "- ‚úÖ Skills system implementation\n",
    "- ‚úÖ Complete control and understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Architecture Map\n",
    "\n",
    "### üèóÔ∏è Agents\n",
    "\n",
    "| Agent | Role | Model | Tools |\n",
    "|-------|------|-------|-------|\n",
    "| **Orchestrator (Main)** | Coordinates all work, talks to user | Nova Lite/Pro | `write_todos`, `read_todos`, `ls`, `read_file`, `write_file`, `edit_file`, `glob_files`, `grep_files`, `load_skill`, `task` |\n",
    "| **Research Sub-agent** | Web research with context isolation | Nova Lite | `tavily_search`, `think_tool` |\n",
    "| **General-purpose Sub-agent** | Any delegated task | Nova Lite | All tools from orchestrator |\n",
    "\n",
    "### üîß Tools by Category\n",
    "\n",
    "| Category | Tool | Description |\n",
    "|----------|------|-------------|\n",
    "| **Planning** | `write_todos` | Create/update TODO list with status tracking |\n",
    "| **Planning** | `read_todos` | Read current TODO list to stay on track |\n",
    "| **Files (Basic)** | `ls` | List all files in virtual filesystem |\n",
    "| **Files (Basic)** | `read_file` | Read file with pagination (offset/limit) |\n",
    "| **Files (Basic)** | `write_file` | Create or overwrite a file |\n",
    "| **Files (Enhanced)** | `edit_file` | Find-and-replace in existing files |\n",
    "| **Files (Enhanced)** | `glob_files` | Find files by pattern (`*.md`, `findings_*`) |\n",
    "| **Files (Enhanced)** | `grep_files` | Search text across all files |\n",
    "| **Skills** | `load_skill` | Load a SKILL.md with detailed instructions |\n",
    "| **Research** | `tavily_search` | Web search + save results to files |\n",
    "| **Research** | `think_tool` | Strategic reflection and planning |\n",
    "| **Delegation** | `task` | Spawn isolated sub-agent for complex tasks |\n",
    "\n",
    "### üìÅ State Schema\n",
    "\n",
    "```python\n",
    "class DeepAgentState(AgentState):\n",
    "    todos: list[Todo]        # Task planning and tracking\n",
    "    files: dict[str, str]    # Virtual filesystem (key=path, value=content)\n",
    "```\n",
    "\n",
    "### üìã TODO Item\n",
    "\n",
    "```python\n",
    "class Todo(TypedDict):\n",
    "    content: str                                    # \"Research MCP protocol\"\n",
    "    status: Literal[\"pending\", \"in_progress\", \"completed\"]  # Current state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What are Skills? (SKILL.md)\n",
    "\n",
    "**Skills** are a concept from the Deep Agents framework for extending agent capabilities via **filesystem-based instruction files**.\n",
    "\n",
    "### How they work:\n",
    "\n",
    "1. A skill is a **directory** containing a `SKILL.md` file\n",
    "2. `SKILL.md` has **YAML frontmatter** (name + description) and **markdown instructions**\n",
    "3. The agent sees only the **name + description** initially (progressive disclosure)\n",
    "4. When the agent decides a skill is relevant, it calls `load_skill(name)` to read the full content\n",
    "\n",
    "### Example SKILL.md:\n",
    "\n",
    "```yaml\n",
    "---\n",
    "name: web-research\n",
    "description: Use this skill for research tasks requiring web searches.\n",
    "---\n",
    "\n",
    "# web-research\n",
    "\n",
    "## Instructions\n",
    "1. Plan your research queries\n",
    "2. Execute searches with tavily_search\n",
    "3. Reflect after each search using think_tool\n",
    "4. Synthesize and deliver findings\n",
    "```\n",
    "\n",
    "### Why skills matter:\n",
    "- Extend capabilities **without adding more tools**\n",
    "- Save **tokens** through progressive disclosure\n",
    "- Provide **domain-specific guidance** (research methodology, code review checklists, etc.)\n",
    "- Easy to create ‚Äî just write a markdown file!\n",
    "\n",
    "> **Note:** The installed `deepagents` library does NOT include the `skills` parameter.\n",
    "> It's a newer feature. Here we implement it **from-scratch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setup & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "from utils import format_messages, show_prompt, stream_agent\n",
    "\n",
    "# --- Model Setup ---\n",
    "llm_nova_lite = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-2-lite-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "llm_nova_pro = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-2-pro-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Choose your model\n",
    "model = llm_nova_lite\n",
    "print(f\"‚úÖ Model loaded: {model.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Import All Tools & Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- State ---\n",
    "from deep_agents_from_scratch.state import DeepAgentState, Todo\n",
    "\n",
    "# --- TODO Tools ---\n",
    "from deep_agents_from_scratch.todo_tools import write_todos, read_todos\n",
    "\n",
    "# --- Basic File Tools (from notebook 2) ---\n",
    "from deep_agents_from_scratch.file_tools import ls, read_file, write_file\n",
    "\n",
    "# --- Enhanced File Tools (NEW) ---\n",
    "from deep_agents_from_scratch.enhanced_file_tools import edit_file, glob_files, grep_files\n",
    "\n",
    "# --- Research Tools ---\n",
    "from deep_agents_from_scratch.research_tools import tavily_search, think_tool\n",
    "\n",
    "# --- Skills ---\n",
    "from deep_agents_from_scratch.skills import (\n",
    "    load_skill,\n",
    "    discover_skills,\n",
    "    get_skills_system_prompt,\n",
    "    RESEARCH_SKILL_MD,\n",
    "    CODE_REVIEW_SKILL_MD,\n",
    ")\n",
    "\n",
    "# --- Task Tool ---\n",
    "from deep_agents_from_scratch.task_tool import _create_task_tool, SubAgent\n",
    "\n",
    "# --- Prompts ---\n",
    "from deep_agents_from_scratch.prompts import (\n",
    "    RESEARCHER_INSTRUCTIONS,\n",
    "    TODO_USAGE_INSTRUCTIONS,\n",
    "    FILE_USAGE_INSTRUCTIONS,\n",
    "    SUBAGENT_USAGE_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ All components imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Review the Enhanced Tools\n",
    "\n",
    "### Enhanced File Tools (NEW)\n",
    "\n",
    "These 3 tools are inspired by the `deepagents` library's `FilesystemMiddleware`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ENHANCED FILE TOOLS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for tool_fn in [edit_file, glob_files, grep_files]:\n",
    "    print(f\"\\nüîß {tool_fn.name}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(tool_fn.description[:200] + \"...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills Tool (NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SKILLS TOOL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüîß {load_skill.name}\")\n",
    "print(\"-\" * 40)\n",
    "print(load_skill.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview: Example Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what a SKILL.md looks like\n",
    "print(\"üìã web-research SKILL.md:\")\n",
    "print(\"=\" * 60)\n",
    "print(RESEARCH_SKILL_MD[:500])\n",
    "print(\"...\")\n",
    "print()\n",
    "\n",
    "# Demonstrate progressive disclosure\n",
    "from deep_agents_from_scratch.skills import parse_skill_md\n",
    "\n",
    "parsed = parse_skill_md(RESEARCH_SKILL_MD)\n",
    "print(\"üîç Progressive Disclosure (what agent sees first):\")\n",
    "print(f\"  Name: {parsed['name']}\")\n",
    "print(f\"  Description: {parsed['description']}\")\n",
    "print(f\"  Instructions length: {len(parsed['instructions'])} chars (loaded on demand)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Build the Enhanced Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# --- All tools for the orchestrator ---\n",
    "orchestrator_tools = [\n",
    "    # Planning\n",
    "    write_todos,\n",
    "    read_todos,\n",
    "    # Basic Files\n",
    "    ls,\n",
    "    read_file,\n",
    "    write_file,\n",
    "    # Enhanced Files (NEW)\n",
    "    edit_file,\n",
    "    glob_files,\n",
    "    grep_files,\n",
    "    # Skills (NEW)\n",
    "    load_skill,\n",
    "    # Research  \n",
    "    think_tool,\n",
    "]\n",
    "\n",
    "# --- Sub-agents ---\n",
    "subagents = [\n",
    "    SubAgent(\n",
    "        name=\"research-agent\",\n",
    "        description=\"Delegated research agent for complex web searches. Has tavily_search and think_tool.\",\n",
    "        prompt=RESEARCHER_INSTRUCTIONS.format(date=datetime.now().strftime(\"%a %b %-d, %Y\")),\n",
    "        tools=[\"tavily_search\", \"think_tool\"],\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Add tavily_search to the tool list (for sub-agent assignment)\n",
    "all_tools_for_registry = orchestrator_tools + [tavily_search]\n",
    "\n",
    "# Create the task delegation tool\n",
    "task_tool = _create_task_tool(\n",
    "    tools=all_tools_for_registry,\n",
    "    subagents=subagents,\n",
    "    model=model,\n",
    "    state_schema=DeepAgentState,\n",
    ")\n",
    "\n",
    "# Final tool list for orchestrator\n",
    "final_tools = orchestrator_tools + [task_tool]\n",
    "\n",
    "print(f\"‚úÖ Orchestrator tools: {len(final_tools)}\")\n",
    "for t in final_tools:\n",
    "    print(f\"   üîß {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Enhanced System Prompt ---\n",
    "ENHANCED_SYSTEM_PROMPT = f\"\"\"You are a highly capable AI assistant with planning, research, file management, and skills capabilities.\n",
    "\n",
    "{TODO_USAGE_INSTRUCTIONS}\n",
    "\n",
    "{FILE_USAGE_INSTRUCTIONS}\n",
    "\n",
    "{SUBAGENT_USAGE_INSTRUCTIONS.format(max_concurrent_research_units=3, max_researcher_iterations=3)}\n",
    "\n",
    "## Skills System\n",
    "You have access to a skills system. Skills are specialized instruction sets loaded from SKILL.md files.\n",
    "- Use `ls()` to discover available skills in the filesystem\n",
    "- Use `load_skill(name)` to read full instructions when a skill is relevant\n",
    "- Skills provide step-by-step guidance for specific tasks (research, code review, etc.)\n",
    "\"\"\"\n",
    "\n",
    "print(\"System prompt length:\", len(ENHANCED_SYSTEM_PROMPT), \"chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create the Enhanced Agent ---\n",
    "enhanced_agent = create_agent(\n",
    "    model,\n",
    "    system_prompt=ENHANCED_SYSTEM_PROMPT,\n",
    "    tools=final_tools,\n",
    "    state_schema=DeepAgentState,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Enhanced agent created!\")\n",
    "print(f\"   Model: {model.model}\")\n",
    "print(f\"   Tools: {len(final_tools)}\")\n",
    "print(f\"   Sub-agents: {len(subagents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Pre-load Skills into the Filesystem\n",
    "\n",
    "We seed the virtual filesystem with our example SKILL.md files.\n",
    "The agent will discover them when it calls `ls()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-load skills into the virtual filesystem\n",
    "initial_files = {\n",
    "    \"/skills/web-research/SKILL.md\": RESEARCH_SKILL_MD,\n",
    "    \"/skills/code-review/SKILL.md\": CODE_REVIEW_SKILL_MD,\n",
    "}\n",
    "\n",
    "# Verify skill discovery works\n",
    "discovered = discover_skills(initial_files)\n",
    "print(\"üìã Discovered Skills:\")\n",
    "for s in discovered:\n",
    "    print(f\"   ‚Ä¢ {s['name']}: {s['description'][:80]}...\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Show the skills system prompt that gets injected\n",
    "skills_prompt = get_skills_system_prompt(initial_files)\n",
    "print(\"üìù Skills System Prompt:\")\n",
    "print(skills_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Test Run ‚Äî Research with Skills\n",
    "\n",
    "Let's test the full enhanced agent. It should:\n",
    "1. Call `ls()` to see the filesystem (including skills)\n",
    "2. Create a TODO plan\n",
    "3. Load relevant skills\n",
    "4. Delegate research to the research sub-agent\n",
    "5. Synthesize and respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test: Research Query ---\n",
    "query = \"Give me an overview of Model Context Protocol (MCP).\"\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": query}],\n",
    "    \"files\": initial_files,  # Pre-load skills\n",
    "}\n",
    "\n",
    "# Run with streaming\n",
    "result = await stream_agent(enhanced_agent, initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final response\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 60)\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View what files were created during the run\n",
    "print(\"\\nüìÅ Files in virtual filesystem:\")\n",
    "for path in result.get(\"files\", {}).keys():\n",
    "    print(f\"   {path}\")\n",
    "\n",
    "# View TODOs\n",
    "print(\"\\nüìã Final TODOs:\")\n",
    "for todo in result.get(\"todos\", []):\n",
    "    status_emoji = {\"pending\": \"‚è≥\", \"in_progress\": \"üîÑ\", \"completed\": \"‚úÖ\"}\n",
    "    emoji = status_emoji.get(todo[\"status\"], \"‚ùì\")\n",
    "    print(f\"   {emoji} {todo['content']} ({todo['status']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Test Enhanced File Tools\n",
    "\n",
    "Let's verify the new `edit_file`, `glob_files`, and `grep_files` work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of enhanced file tools (manual, outside agent)\n",
    "from deep_agents_from_scratch.enhanced_file_tools import edit_file, glob_files, grep_files\n",
    "\n",
    "test_files = {\n",
    "    \"notes.md\": \"# Notes\\n\\nHello World\\nThis is a test.\",\n",
    "    \"findings_mcp.md\": \"# MCP Findings\\n\\nMCP is a protocol for AI communication.\",\n",
    "    \"findings_rag.md\": \"# RAG Findings\\n\\nRAG is retrieval augmented generation.\",\n",
    "    \"readme.txt\": \"Just a readme file.\",\n",
    "}\n",
    "\n",
    "# Test glob\n",
    "print(\"üîç glob_files('findings_*'):\")\n",
    "matches = glob_files.invoke({\"pattern\": \"findings_*\"}, config={\"configurable\": {\"state\": {\"files\": test_files, \"messages\": []}}})\n",
    "print(f\"   {matches}\")\n",
    "\n",
    "# Test grep\n",
    "print(\"\\nüîç grep_files('protocol'):\")\n",
    "grep_result = grep_files.invoke(\n",
    "    {\"pattern\": \"protocol\"}, \n",
    "    config={\"configurable\": {\"state\": {\"files\": test_files, \"messages\": []}}}\n",
    ")\n",
    "print(f\"   {grep_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: From-Scratch vs Library\n",
    "\n",
    "### What we built (from-scratch, Nova compatible):\n",
    "\n",
    "| Feature | From-scratch | Library (`deepagents`) |\n",
    "|---------|-------------|------------------------|\n",
    "| **TODO Tools** | `write_todos` + `read_todos` ‚úÖ | `write_todos` only |\n",
    "| **File Tools** | `ls`, `read_file`, `write_file`, `edit_file`, `glob_files`, `grep_files` ‚úÖ | Same + `execute` |\n",
    "| **Skills** | `load_skill` + SKILL.md parsing ‚úÖ | Newer version only |\n",
    "| **Research** | `tavily_search` + `think_tool` ‚úÖ | ‚ùå Not included |\n",
    "| **Sub-agents** | `task` tool ‚úÖ | `task` tool (more complex middleware) |\n",
    "| **Model** | Nova (Bedrock) ‚úÖ | Claude (Anthropic) |\n",
    "| **Context Management** | Virtual filesystem in state ‚úÖ | Multiple backends (state/disk/store) |\n",
    "\n",
    "### What the library has that we don't (yet):\n",
    "- `execute` tool (sandbox command execution)\n",
    "- `PatchToolCallsMiddleware` (fixing orphaned tool calls)\n",
    "- `SummarizationMiddleware` (compressing long contexts)\n",
    "- Multiple filesystem backends (disk, store, composite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
